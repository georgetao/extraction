{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Outside imports\n",
    "import os\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import train\n",
    "import evaluate\n",
    "import train_util\n",
    "import data_util.data\n",
    "import data_util.batcher\n",
    "import data_util.config\n",
    "import data_util.preprocess\n",
    "\n",
    "importlib.reload(data_util.preprocess)\n",
    "importlib.reload(train)\n",
    "importlib.reload(model)\n",
    "importlib.reload(evaluate)\n",
    "importlib.reload(train_util)\n",
    "importlib.reload(data_util.config)\n",
    "importlib.reload(data_util.data)\n",
    "importlib.reload(data_util.batcher)\n",
    "\n",
    "from train import *\n",
    "from evaluate import *\n",
    "from model import *\n",
    "from train_util import *\n",
    "from data_util.data import *\n",
    "from data_util.batcher import *\n",
    "from data_util.preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_train = pd.read_csv(os.path.join(config.sum_path, 'task_train.tsv'), sep = '\\t')\n",
    "wiki_train = pd.read_csv(os.path.join(config.sum_path, 'wiki_train.tsv'), sep = '\\t')\n",
    "wiki_val   = pd.read_csv(os.path.join(config.sum_path, 'wiki_val.tsv'  ), sep = '\\t')\n",
    "task_val   = pd.read_csv(os.path.join(config.sum_path, 'task_val.tsv'  ), sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_val   = pd.read_csv(os.path.join(config.sum_path, 'task_val.tsv'  ), sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1956, 3)\n",
      "(917986, 3)\n",
      "(300, 3)\n"
     ]
    }
   ],
   "source": [
    "# check sizes\n",
    "print(task_train.shape)\n",
    "print(wiki_train.shape)\n",
    "print(wiki_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Duplicated word in vocabulary file: \"\n",
      "Finished constructing vocabulary of 43861 total words. Last word added: jgsm\n"
     ]
    }
   ],
   "source": [
    "# create vocabulary\n",
    "vocab = Vocab(os.path.join(config.vocab_path, 'vocab3.txt'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument namespace\n",
    "opt = Namespace(\n",
    "    train_mle = \"yes\", \n",
    "    train_rl = \"no\", \n",
    "    mle_weight = 1., \n",
    "    load_model = None,\n",
    "    new_lr = None, \n",
    "    rl_weight = 0.)\n",
    "\n",
    "# create train and val batchers\n",
    "wiki_batcher = TaskBatcher(\n",
    "    examples=wiki_train[:1000].to_dict('records'),\n",
    "    vocab=vocab,\n",
    "    mode='train',\n",
    "    batch_size=16,\n",
    "    single_pass=False\n",
    ")\n",
    "wiki_val_batcher = TaskBatcher( # Batching obj\n",
    "    examples=wiki_val.to_dict('records')[:200],\n",
    "    vocab=vocab, \n",
    "    mode='train', \n",
    "    batch_size=50, \n",
    "    single_pass=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_processor = TaskTrain(vocab, task_batcher, opt, TaskModel, val_task_batcher)\n",
    "wiki_trainer = TaskTrain(vocab, wiki_batcher, opt, TaskModel, wiki_val_batcher)\n",
    "# load pre-trained embedding weights\n",
    "wiki_trainer.model.load_embeddings(\"embedding_43861_200.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 mle_loss: 8.751 mle_loss_val: -100.0000\n",
      "iter: 2 mle_loss: 8.145 mle_loss_val: -100.0000\n",
      "iter: 3 mle_loss: 8.132 mle_loss_val: -100.0000\n",
      "iter: 4 mle_loss: 7.853 mle_loss_val: -100.0000\n",
      "iter: 5 mle_loss: 7.729 mle_loss_val: 7.8103\n",
      "model saved at: \n",
      " data/saved_models/0000005.tar\n",
      "iter: 6 mle_loss: 8.068 mle_loss_val: 7.8103\n",
      "iter: 7 mle_loss: 7.243 mle_loss_val: 7.8103\n",
      "iter: 8 mle_loss: 7.274 mle_loss_val: 7.8103\n",
      "iter: 9 mle_loss: 7.067 mle_loss_val: 7.8103\n",
      "iter: 10 mle_loss: 6.161 mle_loss_val: 5.9920\n",
      "model saved at: \n",
      " data/saved_models/0000010.tar\n",
      "iter: 11 mle_loss: 5.582 mle_loss_val: 5.9920\n",
      "iter: 12 mle_loss: 6.153 mle_loss_val: 5.9920\n",
      "iter: 13 mle_loss: 6.236 mle_loss_val: 5.9920\n",
      "iter: 14 mle_loss: 6.432 mle_loss_val: 5.9920\n",
      "iter: 15 mle_loss: 5.813 mle_loss_val: 5.8314\n",
      "model saved at: \n",
      " data/saved_models/0000015.tar\n",
      "iter: 16 mle_loss: 6.197 mle_loss_val: 5.8314\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "mle_losses = wiki_trainer.trainIters(n_iters=15, report_every=1, save_every = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [(1, 8.751328468322754),\n",
       "  (2, 8.145495414733887),\n",
       "  (3, 8.132192611694336),\n",
       "  (4, 7.853020668029785),\n",
       "  (5, 7.729152679443359),\n",
       "  (6, 8.067704200744629),\n",
       "  (7, 7.242686748504639),\n",
       "  (8, 7.274189472198486),\n",
       "  (9, 7.066506385803223),\n",
       "  (10, 6.160511016845703),\n",
       "  (11, 5.582155227661133),\n",
       "  (12, 6.152600288391113),\n",
       "  (13, 6.235994338989258),\n",
       "  (14, 6.4322710037231445),\n",
       "  (15, 5.812689781188965),\n",
       "  (16, 6.197237968444824)],\n",
       " 'val': [(5, 7.81031060218811),\n",
       "  (10, 5.992038726806641),\n",
       "  (15, 5.8313528299331665)]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mle_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune the Model to Task data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model at data/saved_models/0000015.tar\n"
     ]
    }
   ],
   "source": [
    "# Retrain namespace\n",
    "opt_retrain = Namespace(\n",
    "    train_mle = \"yes\", \n",
    "    train_rl = \"no\", \n",
    "    mle_weight = 1., \n",
    "    load_model = '0000015.tar',\n",
    "    new_lr = None, \n",
    "    rl_weight = 0.)\n",
    "\n",
    "# create train and val batchers for task data\n",
    "task_batcher = TaskBatcher(\n",
    "    examples=task_train.to_dict('records'),\n",
    "    vocab=vocab,\n",
    "    mode='train',\n",
    "    batch_size=16,\n",
    "    single_pass=False\n",
    ")\n",
    "task_val_batcher = TaskBatcher( # Batching obj\n",
    "    examples=task_val.to_dict('records')[:200],\n",
    "    vocab=vocab, \n",
    "    mode='train', \n",
    "    batch_size=50, \n",
    "    single_pass=False\n",
    ")\n",
    "\n",
    "# create (re)trainer\n",
    "task_trainer = TaskTrain(vocab, task_batcher, opt_retrain, TaskModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 mle_loss: 5.016 mle_loss_val: -100.0000\n",
      "iter: 2 mle_loss: 4.740 mle_loss_val: -100.0000\n",
      "iter: 3 mle_loss: 4.947 mle_loss_val: -100.0000\n",
      "model saved at: \n",
      " data/saved_models2//0000003.tar\n",
      "iter: 4 mle_loss: 4.371 mle_loss_val: -100.0000\n"
     ]
    }
   ],
   "source": [
    "config.save_model_path = 'data/saved_models2/'\n",
    "mle_losses_task = task_trainer.trainIters(n_iters=3, report_every=1, save_every = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [(1, 5.0163164138793945),\n",
       "  (2, 4.740086078643799),\n",
       "  (3, 4.947429656982422),\n",
       "  (4, 4.370893478393555)],\n",
       " 'val': []}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mle_losses_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Summaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = os.path.join(config.log_root, \"data/saved_models/0000015.tar\") # model directory\n",
    "\n",
    "# new batcher for evaluation\n",
    "wiki_eval_batcher = TaskBatcher(\n",
    "    examples=wiki_val.to_dict('records'),\n",
    "    vocab=vocab, \n",
    "    mode='train', \n",
    "    batch_size=50,\n",
    "    single_pass=True)\n",
    "\n",
    "task_eval_batcher = TaskBatcher(\n",
    "    examples=task_val.to_dict('records'),\n",
    "    vocab=vocab, \n",
    "    mode='train', \n",
    "    batch_size=50,\n",
    "    single_pass=True)\n",
    "\n",
    "evaluator = TaskEvaluate(vocab, task_eval_batcher, TaskModel, load_model) # Evaluation object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41450470"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# check model parameter count\n",
    "count_parameters(evaluator.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Batch...\n",
      "Summarizing Batch...\n",
      "Summarizing Batch...\n",
      "Summarizing Batch...\n",
      "Summarizing Batch...\n",
      "example_generator completed reading all examples. No more data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rowancassius/Desktop/capstone/LSTM_Summarizer/data_util/batcher.py\", line 445, in text_generator\n",
      "    example = next(example_generator)\n",
      "StopIteration\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rowancassius/opt/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/rowancassius/opt/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rowancassius/Desktop/capstone/LSTM_Summarizer/data_util/batcher.py\", line 426, in fill_example_queue\n",
      "    context, task, summary = next(input_gen) # read the next example from file. article and abstract are both strings.\n",
      "RuntimeError: generator raised StopIteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_generator completed reading all examples. No more data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rowancassius/Desktop/capstone/LSTM_Summarizer/data_util/batcher.py\", line 445, in text_generator\n",
      "    example = next(example_generator)\n",
      "StopIteration\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rowancassius/opt/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/rowancassius/opt/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rowancassius/Desktop/capstone/LSTM_Summarizer/data_util/batcher.py\", line 426, in fill_example_queue\n",
      "    context, task, summary = next(input_gen) # read the next example from file. article and abstract are both strings.\n",
      "RuntimeError: generator raised StopIteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Batch...\n"
     ]
    }
   ],
   "source": [
    "decoded_sents, ref_sents, task_sents, context_sents = evaluator.evaluate_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ref_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(decoded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>ref</th>\n",
       "      <th>decoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>Please use the Alberta Phone Log next to the PX trade app.</td>\n",
       "      <td>use the Alberta phone log</td>\n",
       "      <td>the the the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>But, I'm still here; give me a call when you get a chance - 1586.</td>\n",
       "      <td>call SENDER</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>Christian, could you coordinate the writing of this letter.</td>\n",
       "      <td>coordinate writing of letter</td>\n",
       "      <td>the the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>Please call 1-800-2924-380 , or look on the mailing label from the envelope your GTR was mailed in.</td>\n",
       "      <td>call 1-800-2924 - 380</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>Could you give me a call at your convenience?</td>\n",
       "      <td>call SENDER</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>If okay, please complete and send.</td>\n",
       "      <td>complete document and return to SENDER</td>\n",
       "      <td>please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>Please take a moment to respond to the attached survey.</td>\n",
       "      <td>respond to survey</td>\n",
       "      <td>to to to to to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>Aha, could you provide a column including the approver.</td>\n",
       "      <td>provide column</td>\n",
       "      <td>provide the the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>Can you check Mike Swerzbin for the following deals through Prebon:</td>\n",
       "      <td>check Mike Swerzbin for these deals</td>\n",
       "      <td>check the the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>Could you forward them to me by email?</td>\n",
       "      <td>forward these documents to SENDER</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    task  \\\n",
       "242  Please use the Alberta Phone Log next to the PX trade app.                                            \n",
       "23   But, I'm still here; give me a call when you get a chance - 1586.                                     \n",
       "87   Christian, could you coordinate the writing of this letter.                                           \n",
       "163  Please call 1-800-2924-380 , or look on the mailing label from the envelope your GTR was mailed in.   \n",
       "275  Could you give me a call at your convenience?                                                         \n",
       "287  If okay, please complete and send.                                                                    \n",
       "247  Please take a moment to respond to the attached survey.                                               \n",
       "90   Aha, could you provide a column including the approver.                                               \n",
       "246  Can you check Mike Swerzbin for the following deals through Prebon:                                   \n",
       "116  Could you forward them to me by email?                                                                \n",
       "\n",
       "                                        ref          decoded  \n",
       "242  use the Alberta phone log               the the the      \n",
       "23   call SENDER                                              \n",
       "87   coordinate writing of letter            the the          \n",
       "163  call 1-800-2924 - 380                                    \n",
       "275  call SENDER                                              \n",
       "287  complete document and return to SENDER  please           \n",
       "247  respond to survey                       to to to to to   \n",
       "90   provide column                          provide the the  \n",
       "246  check Mike Swerzbin for these deals     check the the    \n",
       "116  forward these documents to SENDER                        "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'task': task_sents,'ref': ref_sents, 'decoded': decoded_sents})\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
