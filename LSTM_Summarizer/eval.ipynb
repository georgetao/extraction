{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import time\n",
    "\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model import Model\n",
    "\n",
    "from data_util import config, data\n",
    "from data_util.batcher import Batcher\n",
    "from data_util.data import Vocab\n",
    "from train_util import *\n",
    "from beam_search import *\n",
    "from rouge import Rouge\n",
    "import argparse;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cuda(tensor):\n",
    "    if T.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluate(object):\n",
    "    def __init__(self, data_path, opt, batch_size = config.batch_size):\n",
    "        self.vocab = Vocab(config.vocab_path, config.vocab_size)\n",
    "        self.batcher = Batcher(data_path, self.vocab, mode='eval',\n",
    "                               batch_size=batch_size, single_pass=True)\n",
    "        self.opt = opt\n",
    "        time.sleep(5)\n",
    "\n",
    "    def setup_valid(self):\n",
    "        self.model = Model()\n",
    "        self.model = get_cuda(self.model)\n",
    "        checkpoint = T.load(os.path.join(config.save_model_path, self.opt.load_model))\n",
    "        self.model.load_state_dict(checkpoint[\"model_dict\"])\n",
    "\n",
    "\n",
    "    def print_original_predicted(self, decoded_sents, ref_sents, article_sents, loadfile):\n",
    "        filename = \"test_\"+loadfile.split(\".\")[0]+\".txt\"\n",
    "    \n",
    "        with open(os.path.join(\"data\",filename), \"w\") as f:\n",
    "            for i in range(len(decoded_sents)):\n",
    "                f.write(\"article: \"+article_sents[i] + \"\\n\")\n",
    "                f.write(\"ref: \" + ref_sents[i] + \"\\n\")\n",
    "                f.write(\"dec: \" + decoded_sents[i] + \"\\n\\n\")\n",
    "\n",
    "    def evaluate_batch(self, print_sents = False):\n",
    "\n",
    "        self.setup_valid()\n",
    "        batch = self.batcher.next_batch()\n",
    "        start_id = self.vocab.word2id(data.START_DECODING)\n",
    "        end_id = self.vocab.word2id(data.STOP_DECODING)\n",
    "        unk_id = self.vocab.word2id(data.UNKNOWN_TOKEN)\n",
    "        decoded_sents = []\n",
    "        ref_sents = []\n",
    "        article_sents = []\n",
    "        rouge = Rouge()\n",
    "        count = 0\n",
    "        while batch is not None and count < 20:\n",
    "            enc_batch, enc_lens, enc_padding_mask, enc_batch_extend_vocab, extra_zeros, ct_e = get_enc_data(batch)\n",
    "\n",
    "            with T.autograd.no_grad():\n",
    "                enc_batch = self.model.embeds(enc_batch)\n",
    "                enc_out, enc_hidden = self.model.encoder(enc_batch, enc_lens)\n",
    "\n",
    "            #-----------------------Summarization----------------------------------------------------\n",
    "            with T.autograd.no_grad():\n",
    "                pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, self.model, start_id, end_id, unk_id)\n",
    "\n",
    "            for i in range(len(pred_ids)):\n",
    "                decoded_words = data.outputids2words(pred_ids[i], self.vocab, batch.art_oovs[i])\n",
    "                if len(decoded_words) < 2:\n",
    "                    decoded_words = \"xxx\"\n",
    "                else:\n",
    "                    decoded_words = \" \".join(decoded_words)\n",
    "                decoded_sents.append(decoded_words)\n",
    "                abstract = batch.original_abstracts[i]\n",
    "                article = batch.original_articles[i]\n",
    "                ref_sents.append(abstract)\n",
    "                article_sents.append(article)\n",
    "\n",
    "            batch = self.batcher.next_batch()\n",
    "            count += 1\n",
    "            print(batch.original_abstracts)\n",
    "\n",
    "        load_file = self.opt.load_model\n",
    "\n",
    "        if print_sents:\n",
    "            self.print_original_predicted(decoded_sents, ref_sents, article_sents, load_file)\n",
    "\n",
    "        scores = rouge.get_scores(decoded_sents, ref_sents, avg = True)\n",
    "        if self.opt.task == \"test\":\n",
    "            print(load_file, \"scores:\", scores)\n",
    "        else:\n",
    "            rouge_l = scores[\"rouge-l\"][\"f\"]\n",
    "            print(load_file, \"rouge_l:\", \"%.4f\" % rouge_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000001.tar\n",
      "0000002.tar\n",
      "0000003.tar\n",
      "0000004.tar\n",
      "0000005.tar\n",
      "0000006.tar\n",
      "0000007.tar\n",
      "0000008.tar\n",
      "0000009.tar\n",
      "0000010.tar\n",
      "0000011.tar\n"
     ]
    }
   ],
   "source": [
    "task = \"validate\"\n",
    "start_from = \"0000001.tar\" #name of first model -- change this\n",
    "load_model = None\n",
    "\n",
    "opt = Namespace(task = task, start_from = start_from, load_model = load_model)\n",
    "\n",
    "if (opt.task == \"validate\"):\n",
    "    saved_models = os.listdir(config.save_model_path)\n",
    "    saved_models.sort()\n",
    "    file_idx = saved_models.index(start_from)\n",
    "    saved_models = saved_models[file_idx:]\n",
    "    for f in saved_models:\n",
    "        opt.load_model = f\n",
    "        eval_processor = Evaluate(config.valid_data_path, opt)\n",
    "        eval_processor.evaluate_batch(print_sents = True) \n",
    "        print(f)\n",
    "else:   #test\n",
    "    eval_processor = Evaluate(config.test_data_path, opt)\n",
    "    eval_processor.evaluate_batch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
