{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Outside imports\n",
    "import os\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "import model\n",
    "import evaluate\n",
    "import data_util.data\n",
    "import data_util.batcher\n",
    "import data_util.config\n",
    "\n",
    "importlib.reload(model)\n",
    "importlib.reload(train)\n",
    "importlib.reload(evaluate)\n",
    "importlib.reload(data_util.config)\n",
    "importlib.reload(data_util.data)\n",
    "importlib.reload(data_util.batcher)\n",
    "\n",
    "from model import *\n",
    "from train import *\n",
    "from evaluate import *\n",
    "from data_util.data import *\n",
    "from data_util.batcher import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load real data\n",
    "data_path = '/Users/rowancassius/Desktop/capstone/data/context_task_data.tsv'\n",
    "dat = pd.read_csv(data_path, sep='\\t')\n",
    "\n",
    "# test/train split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    dat.TaskSentence.values, \n",
    "    dat.Summary.values,\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# fit tokenizer\n",
    "tokenizer = Tokenizer(lower=True, filters='!\"#$%&()*+,./:;<=>?[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(list(x_train)+list(y_train))\n",
    "\n",
    "# lowercase the data\n",
    "x_train = tokenizer.sequences_to_texts(tokenizer.texts_to_sequences(x_train))\n",
    "y_train = tokenizer.sequences_to_texts(tokenizer.texts_to_sequences(y_train))\n",
    "\n",
    "examples = list(zip(x_train, y_train))\n",
    "# examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "T.manual_seed(123)\n",
    "if T.cuda.is_available():\n",
    "    T.cuda.manual_seed_all(123)\n",
    "    \n",
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_size of vocab was specified as 2829; we now have 2829 words. Stopping reading.\n",
      "Finished constructing vocabulary of 2829 total words. Last word added: foundation\n",
      "INFO:tensorflow:Bucket queue size: 12, Input queue size: 547\n"
     ]
    }
   ],
   "source": [
    "# Standards\n",
    "# Make Vocab\n",
    "vocab = data.Vocab(\n",
    "    words = tokenizer.word_index.keys(), \n",
    "    max_size=len(tokenizer.word_index))\n",
    "\n",
    "# Make Batcher\n",
    "batcher = Batcher(\n",
    "    examples=examples,\n",
    "    vocab=vocab, \n",
    "    mode='train', \n",
    "    batch_size=32, \n",
    "    single_pass=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 32000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 32000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 32000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 32000\n"
     ]
    }
   ],
   "source": [
    "train_mle = \"yes\"\n",
    "train_rl = \"no\"\n",
    "mle_weight = 1.0\n",
    "load_model = None\n",
    "new_lr = None\n",
    "rl_weight = 1 - mle_weight\n",
    "\n",
    "opt = Namespace(train_mle = train_mle, \n",
    "                train_rl = train_rl, \n",
    "                mle_weight = mle_weight, \n",
    "                load_model = load_model,\n",
    "                new_lr = new_lr, \n",
    "                rl_weight = rl_weight)\n",
    "\n",
    "\n",
    "train_processor = Train(vocab, batcher, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processor.setup_train(model=Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_t shape: torch.Size([32])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2])\n",
      "POST embed x_t shape torch.Size([32, 256])\n",
      "final_dist: torch.Size([32, 50000])\n",
      "x_t multinomial: torch.Size([32])\n",
      "x_t shape: torch.Size([32])\n",
      "tensor([  0, 294, 500,  87,   0, 152,  28,  96, 324,  67,  16, 121,  63,  13,\n",
      "         19,  55, 289, 774,  67, 200, 169,  19, 270, 229,  82, 208,  74,  33,\n",
      "        169,  75,  19,  58])\n",
      "POST embed x_t shape torch.Size([32, 256])\n",
      "final_dist: torch.Size([32, 50000])\n",
      "x_t multinomial: torch.Size([32])\n",
      "x_t shape: torch.Size([32])\n",
      "tensor([ 151,    9,   13,   10,   86,    0,   59,   11, 2174,  173,    9, 1817,\n",
      "           0,   61,  163,   17,  971,    0,  112,    0,   37,    9,  979,  230,\n",
      "         962,   89,   48,    4,    0,    6,   28,    0])\n",
      "POST embed x_t shape torch.Size([32, 256])\n",
      "final_dist: torch.Size([32, 50000])\n",
      "x_t multinomial: torch.Size([32])\n",
      "x_t shape: torch.Size([32])\n",
      "tensor([ 13,  20, 975,  86,   4,   0, 107, 963,   0,  13,  17,  13, 118,   0,\n",
      "        906, 494, 499,  20,  11,   7,  11, 740,   4,  13,   1,   4,  12, 969,\n",
      "         11,   6,  31,   0])\n",
      "POST embed x_t shape torch.Size([32, 256])\n",
      "final_dist: torch.Size([32, 50000])\n",
      "x_t multinomial: torch.Size([32])\n",
      "x_t shape: torch.Size([32])\n",
      "tensor([ 414,  247,  127,    1,  101,  374,    1,   38,  560,  221,    0,  967,\n",
      "         966,  951,    6,    7,  972,  584,  965,   85, 2617,    1,  980,  483,\n",
      "           1,  732,  261,   33,   10,    1,    5,    5])\n",
      "POST embed x_t shape torch.Size([32, 256])\n",
      "final_dist: torch.Size([32, 50000])\n",
      "x_t multinomial: torch.Size([32])\n",
      "x_t shape: torch.Size([32])\n",
      "tensor([ 135,  734,    4,   53,    0,  419,    1,   29,  586,    0,    1,  968,\n",
      "           0,   55,  246,   49,    7,    4,    7,   18, 2618,    1,   72,  330,\n",
      "           1,   27, 2616,    0, 1876,    1,    1,    1])\n",
      "POST embed x_t shape torch.Size([32, 256])\n",
      "final_dist: torch.Size([32, 50000])\n",
      "x_t multinomial: torch.Size([32])\n",
      "x_t shape: torch.Size([32])\n",
      "tensor([ 24,  57, 375,   0, 102, 199,   8,   1,  12,   0,   0,   4, 592, 952,\n",
      "        195,   4, 973,   9, 737,   0,  18,   1,   1,  11,   0,   1, 836,   1,\n",
      "          1,   0,   5,   1])\n",
      "POST embed x_t shape torch.Size([32, 256])\n",
      "final_dist: torch.Size([32, 50000])\n",
      "x_t multinomial: torch.Size([32])\n",
      "x_t shape: torch.Size([32])\n",
      "tensor([328, 588,  85,   1,   0,   0,   1,   1, 954,   1,   1, 738,  93,  13,\n",
      "          0,   9,   7,   1,   1,   6, 446,   1,   1,   1,   1,   1,   1,   5,\n",
      "          1,   1,   1,   1])\n",
      "POST embed x_t shape torch.Size([32, 256])\n",
      "final_dist: torch.Size([32, 50000])\n",
      "x_t multinomial: torch.Size([32])\n",
      "x_t shape: torch.Size([32])\n",
      "tensor([   1, 2614,   17,    1,   27,  225,    1,    1,    1,    1,   25,   36,\n",
      "         592,  225,   67,    1, 2554,    0,    1,  329, 2619,    0,    1,    0,\n",
      "         987,    1,    1,   30,    1,    1,    1,    1])\n",
      "POST embed x_t shape torch.Size([32, 256])\n",
      "final_dist: torch.Size([32, 50000])\n",
      "x_t multinomial: torch.Size([32])\n",
      "x_t shape: torch.Size([32])\n",
      "tensor([  1, 415,  15,   1,  70, 213,   1,   1,   1,   1,   1,   0,  17, 185,\n",
      "         85,   1,   0, 953,   1,   0,   0,   1,   0,   1,   0,   1,   1,   1,\n",
      "          1,   1,   1,   1])\n",
      "POST embed x_t shape torch.Size([32, 256])\n",
      "final_dist: torch.Size([32, 50000])\n",
      "x_t multinomial: torch.Size([32])\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 32000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.453962326049805, 0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 32000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 32000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 32000\n"
     ]
    }
   ],
   "source": [
    "train_processor.train_one_batch(train_processor.batcher.next_batch(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Bucket queue size: 21, Input queue size: 352\n"
     ]
    }
   ],
   "source": [
    "# Make Vocab\n",
    "bert_vocab = BertVocab('bert-base-uncased')\n",
    "\n",
    "# Make Batcher\n",
    "bert_batcher = Batcher(\n",
    "    examples=examples,\n",
    "    vocab=bert_vocab, \n",
    "    mode='train', \n",
    "    batch_size=32, \n",
    "    single_pass=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mle = \"yes\"\n",
    "train_rl = \"no\"\n",
    "mle_weight = 1.0\n",
    "load_model = None\n",
    "new_lr = None\n",
    "rl_weight = 1 - mle_weight\n",
    "\n",
    "opt = Namespace(train_mle = train_mle, \n",
    "                train_rl = train_rl, \n",
    "                mle_weight = mle_weight, \n",
    "                load_model = load_model,\n",
    "                new_lr = new_lr, \n",
    "                rl_weight = rl_weight)\n",
    "\n",
    "\n",
    "bert_train_processor = Train(bert_vocab, bert_batcher, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_train_processor.setup_train(model=BertSummarizer)\n",
    "# bert_train_processor.train_one_batch(bert_train_processor.batcher.next_batch(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 32000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 32000\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "bert_train_processor.trainIters(n_iters=5, model=BertSummarizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
