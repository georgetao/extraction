{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Outside imports\n",
    "import os\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import train\n",
    "import evaluate\n",
    "import data_util.data\n",
    "import data_util.batcher\n",
    "import data_util.config\n",
    "\n",
    "\n",
    "importlib.reload(train)\n",
    "importlib.reload(evaluate)\n",
    "importlib.reload(data_util.config)\n",
    "importlib.reload(data_util.data)\n",
    "importlib.reload(data_util.batcher)\n",
    "\n",
    "from train import *\n",
    "from evaluate import *\n",
    "from data_util.data import *\n",
    "from data_util.batcher import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load real data\n",
    "data_path = '/Users/rowancassius/Desktop/capstone/data/context_task_trim.tsv'\n",
    "dat = pd.read_csv(data_path, sep='\\t')\n",
    "\n",
    "# test/train split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    dat.TaskSentence.values, \n",
    "    dat.Summary.values,\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# fit tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list(x_train)+list(y_train))\n",
    "\n",
    "examples = list(zip(x_train, y_train))\n",
    "# examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_size of vocab was specified as 1546; we now have 1546 words. Stopping reading.\n",
      "Finished constructing vocabulary of 1546 total words. Last word added: loi\n",
      "INFO:tensorflow:Bucket queue size: 8, Input queue size: 428\n"
     ]
    }
   ],
   "source": [
    "# Make Vocab\n",
    "vocab = data.Vocab(\n",
    "    words = tokenizer.word_index.keys(), \n",
    "    max_size=len(tokenizer.word_index))\n",
    "\n",
    "# Make Batcher\n",
    "batcher = Batcher(\n",
    "    examples=examples,\n",
    "    vocab=vocab, \n",
    "    mode='train', \n",
    "    batch_size=10, \n",
    "    single_pass=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "T.manual_seed(123)\n",
    "if T.cuda.is_available():\n",
    "    T.cuda.manual_seed_all(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mle = \"yes\"\n",
    "train_rl = \"no\"\n",
    "mle_weight = 1.0\n",
    "load_model = None\n",
    "new_lr = None\n",
    "rl_weight = 1 - mle_weight\n",
    "\n",
    "opt = Namespace(train_mle = train_mle, \n",
    "                train_rl = train_rl, \n",
    "                mle_weight = mle_weight, \n",
    "                load_model = load_model,\n",
    "                new_lr = new_lr, \n",
    "                rl_weight = rl_weight)\n",
    "\n",
    "\n",
    "train_processor = Train(vocab, batcher, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "iter: 5 mle_loss: 8.556 reward: 0.0000\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "iter: 10 mle_loss: 6.686 reward: 0.0000\n",
      "model saved at: \n",
      " data/saved_models/0000010.tar\n",
      "10\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n"
     ]
    }
   ],
   "source": [
    "train_processor.trainIters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_generator completed reading all examples. No more data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rowancassius/Desktop/capstone/LSTM_Summarizer/data_util/batcher.py\", line 273, in text_generator\n",
      "    e = next(example_generator) # e is a tf.Example\n",
      "StopIteration\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rowancassius/opt/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/rowancassius/opt/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rowancassius/Desktop/capstone/LSTM_Summarizer/data_util/batcher.py\", line 207, in fill_example_queue\n",
      "    (article, abstract) = next(input_gen) # read the next example from file. article and abstract are both strings.\n",
      "RuntimeError: generator raised StopIteration\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task = \"validate\"\n",
    "load_model = os.path.join(config.log_root, \"data/saved_models/0000010.tar\")\n",
    "\n",
    "opt = Namespace(task = task, load_model = load_model)\n",
    "\n",
    "# new batcher for evaluation\n",
    "batcher = Batcher(\n",
    "    examples=examples[:20],\n",
    "    vocab=vocab, \n",
    "    mode='train', \n",
    "    batch_size=10, \n",
    "    single_pass=True)\n",
    "\n",
    "eval_processor = Evaluate(vocab, batcher, opt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Batch...\n",
      "Summarizing Batch...\n",
      "INFO:tensorflow:Finished reading dataset in single_pass mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['xxx',\n",
       "  'xxx',\n",
       "  'xxx',\n",
       "  'xxx',\n",
       "  'xxx',\n",
       "  'xxx',\n",
       "  'xxx',\n",
       "  'xxx',\n",
       "  'Please Chris Germany@enron.com Germany@enron.com',\n",
       "  'Can look? look? look?',\n",
       "  'xxx',\n",
       "  'xxx',\n",
       "  'xxx',\n",
       "  'xxx',\n",
       "  'xxx',\n",
       "  'xxx',\n",
       "  'Please Ellen.',\n",
       "  'Can tomorrow? tomorrow?',\n",
       "  'Give call. call. call.',\n",
       "  'Please scroll down down down'],\n",
       " ['Open ECT Address Book',\n",
       "  'Attend meeting about responsibilities in maintaining the Kerr McGee tickets in Sitara',\n",
       "  \"Insert appropriate Seller's Payment\",\n",
       "  'Review Alberta PPA presentation',\n",
       "  'Review filing with the FERC and send coments to Mollie Lampi',\n",
       "  'Complete survey',\n",
       "  'Put SENDER on cc list for Wellesley',\n",
       "  'Examine this and call SENDER',\n",
       "  'Reply to Chris at Germany@enron.com',\n",
       "  'Look at definition for diesel index',\n",
       "  'Donate this money',\n",
       "  'Create swaps today',\n",
       "  'Supply Portland at their system',\n",
       "  'Call SENDER',\n",
       "  'Check work phone for Joseph Brophy',\n",
       "  'Call SENDER or Tracy Cummins at 713-8566-525',\n",
       "  'Run minibook and forward to Ellen',\n",
       "  'Meet with SENDER tomorrow',\n",
       "  'Call SENDER about March Aeco product',\n",
       "  'Scroll down'],\n",
       " {'rouge-1': {'f': 0.05178571364413267, 'p': 0.06, 'r': 0.05833333333333333},\n",
       "  'rouge-2': {'f': 0.009999999750000007, 'p': 0.01, 'r': 0.01},\n",
       "  'rouge-l': {'f': 0.062499999332500014,\n",
       "   'p': 0.07916666666666666,\n",
       "   'r': 0.05833333333333333}})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n",
      "INFO:tensorflow:Bucket queue size: 1000, Input queue size: 10000\n"
     ]
    }
   ],
   "source": [
    "eval_processor.evaluate_batch(print_sents = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
