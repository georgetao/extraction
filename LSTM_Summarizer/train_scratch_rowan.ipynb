{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outside imports\n",
    "import os\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import train\n",
    "import evaluate\n",
    "import train_util\n",
    "import data_util.data\n",
    "import data_util.batcher\n",
    "import data_util.config\n",
    "import data_util.preprocess\n",
    "\n",
    "importlib.reload(data_util.preprocess)\n",
    "importlib.reload(train)\n",
    "importlib.reload(model)\n",
    "importlib.reload(evaluate)\n",
    "importlib.reload(train_util)\n",
    "importlib.reload(data_util.config)\n",
    "importlib.reload(data_util.data)\n",
    "importlib.reload(data_util.batcher)\n",
    "\n",
    "from train import *\n",
    "from evaluate import *\n",
    "from model import *\n",
    "from train_util import *\n",
    "from data_util.data import *\n",
    "from data_util.batcher import *\n",
    "from data_util.preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load real data\n",
    "data_path = os.path.join(config.log_root, 'data/context_task_data.tsv')\n",
    "dat = pd.read_csv(data_path, sep='\\t')\n",
    "\n",
    "# fill nas\n",
    "dat.fillna('', inplace=True)\n",
    "\n",
    "# train/test split\n",
    "np.random.seed(111)\n",
    "dat = dat.sample(frac=1)\n",
    "\n",
    "train_size = int(.8*dat.shape[0])\n",
    "train_data = dat[:train_size]\n",
    "test_data = dat[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the the data\n",
    "def prep_data(df):\n",
    "    df['Context'] = df['Context'].map(lambda x: article_process_text(x))\n",
    "    df['TaskSentence'] = df['TaskSentence'].map(lambda x: article_process_text(x))\n",
    "    df['Summary'] = df['Summary'].map(lambda x: summary_process_text(x))\n",
    "    return df\n",
    "train_data = prep_data(train_data)\n",
    "test_data = prep_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: <s>, </s>, [UNK], [PAD], [START] or [STOP] found in vocab file\n",
      "WARNING: <s>, </s>, [UNK], [PAD], [START] or [STOP] found in vocab file\n",
      "WARNING: <s>, </s>, [UNK], [PAD], [START] or [STOP] found in vocab file\n",
      "WARNING: <s>, </s>, [UNK], [PAD], [START] or [STOP] found in vocab file\n",
      "Finished constructing vocabulary of 6639 total words. Last word added: LANGUAGE\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab(os.path.join(config.log_root, 'data/vocab/vocab.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "T.manual_seed(123)\n",
    "if T.cuda.is_available():\n",
    "    T.cuda.manual_seed_all(123)\n",
    "    \n",
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mle = \"yes\"\n",
    "train_rl = \"no\"\n",
    "mle_weight = 1.0\n",
    "load_model = None\n",
    "new_lr = None\n",
    "rl_weight = 1 - mle_weight\n",
    "\n",
    "opt = Namespace(train_mle = train_mle, \n",
    "                train_rl = train_rl, \n",
    "                mle_weight = mle_weight, \n",
    "                load_model = load_model,\n",
    "                new_lr = new_lr, \n",
    "                rl_weight = rl_weight)\n",
    "\n",
    "task_batcher = TaskBatcher(\n",
    "    examples=train_data.to_dict('records'),\n",
    "    vocab=vocab,\n",
    "    mode='train',\n",
    "    batch_size=32,\n",
    "    single_pass=False\n",
    ")\n",
    "\n",
    "val_task_batcher = TaskBatcher( # Batching obj\n",
    "    examples=test_data.to_dict('records')[:200],\n",
    "    vocab=vocab, \n",
    "    mode='train', \n",
    "    batch_size=50, \n",
    "    single_pass=False\n",
    ")\n",
    "\n",
    "\n",
    "train_processor = TaskTrain(vocab, task_batcher, opt, TaskModel, val_task_batcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained embedding weights\n",
    "train_processor.model.load_embeddings(\"embedding_6639_200.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 mle_loss: 6.156 mle_loss_val: -100.0000\n",
      "iter: 2 mle_loss: 5.996 mle_loss_val: -100.0000\n",
      "iter: 3 mle_loss: 6.573 mle_loss_val: -100.0000\n",
      "iter: 4 mle_loss: 5.907 mle_loss_val: -100.0000\n",
      "iter: 5 mle_loss: 5.893 mle_loss_val: -100.0000\n",
      "iter: 6 mle_loss: 5.372 mle_loss_val: -100.0000\n",
      "iter: 7 mle_loss: 4.603 mle_loss_val: -100.0000\n",
      "iter: 8 mle_loss: 4.012 mle_loss_val: -100.0000\n",
      "iter: 9 mle_loss: 4.355 mle_loss_val: -100.0000\n",
      "iter: 10 mle_loss: 3.586 mle_loss_val: -100.0000\n",
      "iter: 11 mle_loss: 3.572 mle_loss_val: -100.0000\n",
      "iter: 12 mle_loss: 3.766 mle_loss_val: -100.0000\n",
      "iter: 13 mle_loss: 3.235 mle_loss_val: -100.0000\n",
      "iter: 14 mle_loss: 2.986 mle_loss_val: -100.0000\n",
      "iter: 15 mle_loss: 3.070 mle_loss_val: -100.0000\n",
      "iter: 16 mle_loss: 3.145 mle_loss_val: -100.0000\n",
      "iter: 17 mle_loss: 3.135 mle_loss_val: -100.0000\n",
      "iter: 18 mle_loss: 3.109 mle_loss_val: -100.0000\n",
      "iter: 19 mle_loss: 2.955 mle_loss_val: -100.0000\n",
      "iter: 20 mle_loss: 3.421 mle_loss_val: 3.0396\n",
      "model saved at: \n",
      " data/saved_models/0000020.tar\n",
      "iter: 21 mle_loss: 2.831 mle_loss_val: 3.0396\n",
      "iter: 22 mle_loss: 2.740 mle_loss_val: 3.0396\n",
      "iter: 23 mle_loss: 3.019 mle_loss_val: 3.0396\n",
      "iter: 24 mle_loss: 3.008 mle_loss_val: 3.0396\n",
      "iter: 25 mle_loss: 2.887 mle_loss_val: 3.0396\n",
      "iter: 26 mle_loss: 2.494 mle_loss_val: 3.0396\n",
      "iter: 27 mle_loss: 2.959 mle_loss_val: 3.0396\n",
      "iter: 28 mle_loss: 3.061 mle_loss_val: 3.0396\n",
      "iter: 29 mle_loss: 2.967 mle_loss_val: 3.0396\n",
      "iter: 30 mle_loss: 2.815 mle_loss_val: 3.0396\n",
      "iter: 31 mle_loss: 2.957 mle_loss_val: 3.0396\n",
      "iter: 32 mle_loss: 2.992 mle_loss_val: 3.0396\n",
      "iter: 33 mle_loss: 2.744 mle_loss_val: 3.0396\n",
      "iter: 34 mle_loss: 2.756 mle_loss_val: 3.0396\n",
      "iter: 35 mle_loss: 2.779 mle_loss_val: 3.0396\n",
      "iter: 36 mle_loss: 3.003 mle_loss_val: 3.0396\n",
      "iter: 37 mle_loss: 2.879 mle_loss_val: 3.0396\n",
      "iter: 38 mle_loss: 2.849 mle_loss_val: 3.0396\n",
      "iter: 39 mle_loss: 3.242 mle_loss_val: 3.0396\n",
      "iter: 40 mle_loss: 2.558 mle_loss_val: 2.7719\n",
      "model saved at: \n",
      " data/saved_models/0000040.tar\n",
      "iter: 41 mle_loss: 2.598 mle_loss_val: 2.7719\n",
      "iter: 42 mle_loss: 2.766 mle_loss_val: 2.7719\n",
      "iter: 43 mle_loss: 2.658 mle_loss_val: 2.7719\n",
      "iter: 44 mle_loss: 2.664 mle_loss_val: 2.7719\n",
      "iter: 45 mle_loss: 2.506 mle_loss_val: 2.7719\n",
      "iter: 46 mle_loss: 2.705 mle_loss_val: 2.7719\n",
      "iter: 47 mle_loss: 2.391 mle_loss_val: 2.7719\n",
      "iter: 48 mle_loss: 2.726 mle_loss_val: 2.7719\n",
      "iter: 49 mle_loss: 2.841 mle_loss_val: 2.7719\n",
      "iter: 50 mle_loss: 2.242 mle_loss_val: 2.7719\n",
      "iter: 51 mle_loss: 2.778 mle_loss_val: 2.7719\n",
      "iter: 52 mle_loss: 2.770 mle_loss_val: 2.7719\n",
      "iter: 53 mle_loss: 2.795 mle_loss_val: 2.7719\n",
      "iter: 54 mle_loss: 2.578 mle_loss_val: 2.7719\n",
      "iter: 55 mle_loss: 2.824 mle_loss_val: 2.7719\n",
      "iter: 56 mle_loss: 2.807 mle_loss_val: 2.7719\n",
      "iter: 57 mle_loss: 2.780 mle_loss_val: 2.7719\n",
      "iter: 58 mle_loss: 2.392 mle_loss_val: 2.7719\n",
      "iter: 59 mle_loss: 2.893 mle_loss_val: 2.7719\n",
      "iter: 60 mle_loss: 2.338 mle_loss_val: 2.6092\n",
      "model saved at: \n",
      " data/saved_models/0000060.tar\n",
      "iter: 61 mle_loss: 2.394 mle_loss_val: 2.6092\n",
      "iter: 62 mle_loss: 2.837 mle_loss_val: 2.6092\n",
      "iter: 63 mle_loss: 2.582 mle_loss_val: 2.6092\n",
      "iter: 64 mle_loss: 2.429 mle_loss_val: 2.6092\n",
      "iter: 65 mle_loss: 2.480 mle_loss_val: 2.6092\n",
      "iter: 66 mle_loss: 2.572 mle_loss_val: 2.6092\n",
      "iter: 67 mle_loss: 2.778 mle_loss_val: 2.6092\n",
      "iter: 68 mle_loss: 2.198 mle_loss_val: 2.6092\n",
      "iter: 69 mle_loss: 2.226 mle_loss_val: 2.6092\n",
      "iter: 70 mle_loss: 2.766 mle_loss_val: 2.6092\n",
      "iter: 71 mle_loss: 2.382 mle_loss_val: 2.6092\n",
      "iter: 72 mle_loss: 2.437 mle_loss_val: 2.6092\n",
      "iter: 73 mle_loss: 2.229 mle_loss_val: 2.6092\n",
      "iter: 74 mle_loss: 2.734 mle_loss_val: 2.6092\n",
      "iter: 75 mle_loss: 2.642 mle_loss_val: 2.6092\n",
      "iter: 76 mle_loss: 2.257 mle_loss_val: 2.6092\n",
      "iter: 77 mle_loss: 2.535 mle_loss_val: 2.6092\n",
      "iter: 78 mle_loss: 2.548 mle_loss_val: 2.6092\n",
      "iter: 79 mle_loss: 2.430 mle_loss_val: 2.6092\n",
      "iter: 80 mle_loss: 2.066 mle_loss_val: 2.4432\n",
      "model saved at: \n",
      " data/saved_models/0000080.tar\n",
      "iter: 81 mle_loss: 2.585 mle_loss_val: 2.4432\n",
      "iter: 82 mle_loss: 2.194 mle_loss_val: 2.4432\n",
      "iter: 83 mle_loss: 2.394 mle_loss_val: 2.4432\n",
      "iter: 84 mle_loss: 1.723 mle_loss_val: 2.4432\n",
      "iter: 85 mle_loss: 2.386 mle_loss_val: 2.4432\n",
      "iter: 86 mle_loss: 2.205 mle_loss_val: 2.4432\n",
      "iter: 87 mle_loss: 2.353 mle_loss_val: 2.4432\n",
      "iter: 88 mle_loss: 2.376 mle_loss_val: 2.4432\n",
      "iter: 89 mle_loss: 2.212 mle_loss_val: 2.4432\n",
      "iter: 90 mle_loss: 2.476 mle_loss_val: 2.4432\n",
      "iter: 91 mle_loss: 2.189 mle_loss_val: 2.4432\n",
      "iter: 92 mle_loss: 2.210 mle_loss_val: 2.4432\n",
      "iter: 93 mle_loss: 2.116 mle_loss_val: 2.4432\n",
      "iter: 94 mle_loss: 2.030 mle_loss_val: 2.4432\n",
      "iter: 95 mle_loss: 2.594 mle_loss_val: 2.4432\n",
      "iter: 96 mle_loss: 2.364 mle_loss_val: 2.4432\n",
      "iter: 97 mle_loss: 2.038 mle_loss_val: 2.4432\n",
      "iter: 98 mle_loss: 2.233 mle_loss_val: 2.4432\n",
      "iter: 99 mle_loss: 2.526 mle_loss_val: 2.4432\n",
      "iter: 100 mle_loss: 2.068 mle_loss_val: 2.3713\n",
      "model saved at: \n",
      " data/saved_models/0000100.tar\n",
      "iter: 101 mle_loss: 2.331 mle_loss_val: 2.3713\n",
      "iter: 102 mle_loss: 2.485 mle_loss_val: 2.3713\n",
      "iter: 103 mle_loss: 2.134 mle_loss_val: 2.3713\n",
      "iter: 104 mle_loss: 2.400 mle_loss_val: 2.3713\n",
      "iter: 105 mle_loss: 2.057 mle_loss_val: 2.3713\n",
      "iter: 106 mle_loss: 2.306 mle_loss_val: 2.3713\n",
      "iter: 107 mle_loss: 2.177 mle_loss_val: 2.3713\n",
      "iter: 108 mle_loss: 2.548 mle_loss_val: 2.3713\n",
      "iter: 109 mle_loss: 2.568 mle_loss_val: 2.3713\n",
      "iter: 110 mle_loss: 2.336 mle_loss_val: 2.3713\n",
      "iter: 111 mle_loss: 2.039 mle_loss_val: 2.3713\n",
      "iter: 112 mle_loss: 2.421 mle_loss_val: 2.3713\n",
      "iter: 113 mle_loss: 2.177 mle_loss_val: 2.3713\n",
      "iter: 114 mle_loss: 2.413 mle_loss_val: 2.3713\n",
      "iter: 115 mle_loss: 1.959 mle_loss_val: 2.3713\n",
      "iter: 116 mle_loss: 2.085 mle_loss_val: 2.3713\n",
      "iter: 117 mle_loss: 2.285 mle_loss_val: 2.3713\n",
      "iter: 118 mle_loss: 2.226 mle_loss_val: 2.3713\n",
      "iter: 119 mle_loss: 2.489 mle_loss_val: 2.3713\n",
      "iter: 120 mle_loss: 2.024 mle_loss_val: 2.4043\n",
      "model saved at: \n",
      " data/saved_models/0000120.tar\n",
      "iter: 121 mle_loss: 2.142 mle_loss_val: 2.4043\n",
      "iter: 122 mle_loss: 2.499 mle_loss_val: 2.4043\n",
      "iter: 123 mle_loss: 2.473 mle_loss_val: 2.4043\n",
      "iter: 124 mle_loss: 2.059 mle_loss_val: 2.4043\n",
      "iter: 125 mle_loss: 2.370 mle_loss_val: 2.4043\n",
      "iter: 126 mle_loss: 2.418 mle_loss_val: 2.4043\n",
      "iter: 127 mle_loss: 2.565 mle_loss_val: 2.4043\n",
      "iter: 128 mle_loss: 2.174 mle_loss_val: 2.4043\n",
      "iter: 129 mle_loss: 2.319 mle_loss_val: 2.4043\n",
      "iter: 130 mle_loss: 2.183 mle_loss_val: 2.4043\n",
      "iter: 131 mle_loss: 1.997 mle_loss_val: 2.4043\n",
      "iter: 132 mle_loss: 2.369 mle_loss_val: 2.4043\n",
      "iter: 133 mle_loss: 2.392 mle_loss_val: 2.4043\n",
      "iter: 134 mle_loss: 2.071 mle_loss_val: 2.4043\n",
      "iter: 135 mle_loss: 2.399 mle_loss_val: 2.4043\n",
      "iter: 136 mle_loss: 1.823 mle_loss_val: 2.4043\n",
      "iter: 137 mle_loss: 2.301 mle_loss_val: 2.4043\n",
      "iter: 138 mle_loss: 2.357 mle_loss_val: 2.4043\n",
      "iter: 139 mle_loss: 1.731 mle_loss_val: 2.4043\n",
      "iter: 140 mle_loss: 1.940 mle_loss_val: 2.3007\n",
      "model saved at: \n",
      " data/saved_models/0000140.tar\n",
      "iter: 141 mle_loss: 2.373 mle_loss_val: 2.3007\n",
      "iter: 142 mle_loss: 2.150 mle_loss_val: 2.3007\n",
      "iter: 143 mle_loss: 2.131 mle_loss_val: 2.3007\n",
      "iter: 144 mle_loss: 2.023 mle_loss_val: 2.3007\n",
      "iter: 145 mle_loss: 2.277 mle_loss_val: 2.3007\n",
      "iter: 146 mle_loss: 2.226 mle_loss_val: 2.3007\n",
      "iter: 147 mle_loss: 2.147 mle_loss_val: 2.3007\n",
      "iter: 148 mle_loss: 2.425 mle_loss_val: 2.3007\n",
      "iter: 149 mle_loss: 2.011 mle_loss_val: 2.3007\n",
      "iter: 150 mle_loss: 1.986 mle_loss_val: 2.3007\n",
      "iter: 151 mle_loss: 2.103 mle_loss_val: 2.3007\n",
      "iter: 152 mle_loss: 2.084 mle_loss_val: 2.3007\n",
      "iter: 153 mle_loss: 2.091 mle_loss_val: 2.3007\n",
      "iter: 154 mle_loss: 1.877 mle_loss_val: 2.3007\n",
      "iter: 155 mle_loss: 1.981 mle_loss_val: 2.3007\n",
      "iter: 156 mle_loss: 1.837 mle_loss_val: 2.3007\n",
      "iter: 157 mle_loss: 2.098 mle_loss_val: 2.3007\n",
      "iter: 158 mle_loss: 2.234 mle_loss_val: 2.3007\n",
      "iter: 159 mle_loss: 2.040 mle_loss_val: 2.3007\n",
      "iter: 160 mle_loss: 1.934 mle_loss_val: 2.2549\n",
      "model saved at: \n",
      " data/saved_models/0000160.tar\n",
      "iter: 161 mle_loss: 2.284 mle_loss_val: 2.2549\n",
      "iter: 162 mle_loss: 1.946 mle_loss_val: 2.2549\n",
      "iter: 163 mle_loss: 1.817 mle_loss_val: 2.2549\n",
      "iter: 164 mle_loss: 2.050 mle_loss_val: 2.2549\n",
      "iter: 165 mle_loss: 2.167 mle_loss_val: 2.2549\n",
      "iter: 166 mle_loss: 2.099 mle_loss_val: 2.2549\n",
      "iter: 167 mle_loss: 1.851 mle_loss_val: 2.2549\n",
      "iter: 168 mle_loss: 2.065 mle_loss_val: 2.2549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 169 mle_loss: 2.004 mle_loss_val: 2.2549\n",
      "iter: 170 mle_loss: 2.059 mle_loss_val: 2.2549\n",
      "iter: 171 mle_loss: 1.989 mle_loss_val: 2.2549\n",
      "iter: 172 mle_loss: 2.192 mle_loss_val: 2.2549\n",
      "iter: 173 mle_loss: 2.089 mle_loss_val: 2.2549\n",
      "iter: 174 mle_loss: 1.996 mle_loss_val: 2.2549\n",
      "iter: 175 mle_loss: 1.869 mle_loss_val: 2.2549\n",
      "iter: 176 mle_loss: 2.119 mle_loss_val: 2.2549\n",
      "iter: 177 mle_loss: 2.182 mle_loss_val: 2.2549\n",
      "iter: 178 mle_loss: 2.271 mle_loss_val: 2.2549\n",
      "iter: 179 mle_loss: 2.300 mle_loss_val: 2.2549\n",
      "iter: 180 mle_loss: 2.272 mle_loss_val: 2.2279\n",
      "model saved at: \n",
      " data/saved_models/0000180.tar\n",
      "iter: 181 mle_loss: 2.091 mle_loss_val: 2.2279\n",
      "iter: 182 mle_loss: 1.780 mle_loss_val: 2.2279\n",
      "iter: 183 mle_loss: 2.153 mle_loss_val: 2.2279\n",
      "iter: 184 mle_loss: 1.972 mle_loss_val: 2.2279\n",
      "iter: 185 mle_loss: 1.965 mle_loss_val: 2.2279\n",
      "iter: 186 mle_loss: 1.742 mle_loss_val: 2.2279\n",
      "iter: 187 mle_loss: 2.026 mle_loss_val: 2.2279\n",
      "iter: 188 mle_loss: 1.765 mle_loss_val: 2.2279\n",
      "iter: 189 mle_loss: 2.309 mle_loss_val: 2.2279\n",
      "iter: 190 mle_loss: 2.277 mle_loss_val: 2.2279\n",
      "iter: 191 mle_loss: 1.573 mle_loss_val: 2.2279\n",
      "iter: 192 mle_loss: 2.109 mle_loss_val: 2.2279\n",
      "iter: 193 mle_loss: 2.213 mle_loss_val: 2.2279\n",
      "iter: 194 mle_loss: 2.039 mle_loss_val: 2.2279\n",
      "iter: 195 mle_loss: 1.972 mle_loss_val: 2.2279\n",
      "iter: 196 mle_loss: 2.249 mle_loss_val: 2.2279\n",
      "iter: 197 mle_loss: 2.305 mle_loss_val: 2.2279\n",
      "iter: 198 mle_loss: 2.260 mle_loss_val: 2.2279\n",
      "iter: 199 mle_loss: 1.664 mle_loss_val: 2.2279\n",
      "iter: 200 mle_loss: 2.393 mle_loss_val: 2.2365\n",
      "model saved at: \n",
      " data/saved_models/0000200.tar\n",
      "iter: 201 mle_loss: 1.874 mle_loss_val: 2.2365\n"
     ]
    }
   ],
   "source": [
    "config.save_model_path = \"data/saved_models\"\n",
    "\n",
    "mle_losses = train_processor.trainIters(n_iters=200, report_every=1, save_every = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [(1, 6.156216144561768),\n",
       "  (2, 5.995687961578369),\n",
       "  (3, 6.572842597961426),\n",
       "  (4, 5.907210350036621),\n",
       "  (5, 5.893364429473877),\n",
       "  (6, 5.371551036834717),\n",
       "  (7, 4.602599143981934),\n",
       "  (8, 4.011568546295166),\n",
       "  (9, 4.354945659637451),\n",
       "  (10, 3.58575439453125),\n",
       "  (11, 3.5724947452545166),\n",
       "  (12, 3.7657856941223145),\n",
       "  (13, 3.235222816467285),\n",
       "  (14, 2.985779047012329),\n",
       "  (15, 3.070305585861206),\n",
       "  (16, 3.145054578781128),\n",
       "  (17, 3.135206937789917),\n",
       "  (18, 3.108992099761963),\n",
       "  (19, 2.955451488494873),\n",
       "  (20, 3.421107769012451),\n",
       "  (21, 2.831132650375366),\n",
       "  (22, 2.7401914596557617),\n",
       "  (23, 3.0186681747436523),\n",
       "  (24, 3.007930278778076),\n",
       "  (25, 2.887131929397583),\n",
       "  (26, 2.494403123855591),\n",
       "  (27, 2.9594056606292725),\n",
       "  (28, 3.0613701343536377),\n",
       "  (29, 2.967100143432617),\n",
       "  (30, 2.8152413368225098),\n",
       "  (31, 2.9568252563476562),\n",
       "  (32, 2.9920711517333984),\n",
       "  (33, 2.743544578552246),\n",
       "  (34, 2.7561545372009277),\n",
       "  (35, 2.779202461242676),\n",
       "  (36, 3.0034172534942627),\n",
       "  (37, 2.8787875175476074),\n",
       "  (38, 2.8485031127929688),\n",
       "  (39, 3.2416441440582275),\n",
       "  (40, 2.5581605434417725),\n",
       "  (41, 2.5981695652008057),\n",
       "  (42, 2.766493558883667),\n",
       "  (43, 2.6581311225891113),\n",
       "  (44, 2.6638736724853516),\n",
       "  (45, 2.5064690113067627),\n",
       "  (46, 2.705471992492676),\n",
       "  (47, 2.3905465602874756),\n",
       "  (48, 2.725767135620117),\n",
       "  (49, 2.841198444366455),\n",
       "  (50, 2.2417824268341064),\n",
       "  (51, 2.7776541709899902),\n",
       "  (52, 2.7697081565856934),\n",
       "  (53, 2.794820785522461),\n",
       "  (54, 2.577937602996826),\n",
       "  (55, 2.8243722915649414),\n",
       "  (56, 2.806802272796631),\n",
       "  (57, 2.780374526977539),\n",
       "  (58, 2.3920602798461914),\n",
       "  (59, 2.8934826850891113),\n",
       "  (60, 2.338392734527588),\n",
       "  (61, 2.393827438354492),\n",
       "  (62, 2.836853504180908),\n",
       "  (63, 2.5818231105804443),\n",
       "  (64, 2.4288642406463623),\n",
       "  (65, 2.4801406860351562),\n",
       "  (66, 2.571686267852783),\n",
       "  (67, 2.7780117988586426),\n",
       "  (68, 2.1978836059570312),\n",
       "  (69, 2.226309299468994),\n",
       "  (70, 2.7658162117004395),\n",
       "  (71, 2.3823916912078857),\n",
       "  (72, 2.436859607696533),\n",
       "  (73, 2.228651762008667),\n",
       "  (74, 2.733626127243042),\n",
       "  (75, 2.641909122467041),\n",
       "  (76, 2.2574496269226074),\n",
       "  (77, 2.5352017879486084),\n",
       "  (78, 2.547800302505493),\n",
       "  (79, 2.430128574371338),\n",
       "  (80, 2.065882444381714),\n",
       "  (81, 2.585416078567505),\n",
       "  (82, 2.193974018096924),\n",
       "  (83, 2.3936166763305664),\n",
       "  (84, 1.7227706909179688),\n",
       "  (85, 2.386086940765381),\n",
       "  (86, 2.2049529552459717),\n",
       "  (87, 2.3529627323150635),\n",
       "  (88, 2.3760104179382324),\n",
       "  (89, 2.212273597717285),\n",
       "  (90, 2.476344347000122),\n",
       "  (91, 2.188642740249634),\n",
       "  (92, 2.2101330757141113),\n",
       "  (93, 2.1161253452301025),\n",
       "  (94, 2.0295794010162354),\n",
       "  (95, 2.5937318801879883),\n",
       "  (96, 2.364423990249634),\n",
       "  (97, 2.037829875946045),\n",
       "  (98, 2.233304023742676),\n",
       "  (99, 2.5255699157714844),\n",
       "  (100, 2.0683414936065674),\n",
       "  (101, 2.330986976623535),\n",
       "  (102, 2.485332489013672),\n",
       "  (103, 2.134493827819824),\n",
       "  (104, 2.3995518684387207),\n",
       "  (105, 2.0571067333221436),\n",
       "  (106, 2.305840492248535),\n",
       "  (107, 2.1765449047088623),\n",
       "  (108, 2.5481302738189697),\n",
       "  (109, 2.56835675239563),\n",
       "  (110, 2.336047649383545),\n",
       "  (111, 2.039184808731079),\n",
       "  (112, 2.420929431915283),\n",
       "  (113, 2.1774942874908447),\n",
       "  (114, 2.4133987426757812),\n",
       "  (115, 1.9591541290283203),\n",
       "  (116, 2.085455894470215),\n",
       "  (117, 2.284825325012207),\n",
       "  (118, 2.226240634918213),\n",
       "  (119, 2.489144802093506),\n",
       "  (120, 2.02411150932312),\n",
       "  (121, 2.141650915145874),\n",
       "  (122, 2.4988510608673096),\n",
       "  (123, 2.473341464996338),\n",
       "  (124, 2.058546543121338),\n",
       "  (125, 2.3702163696289062),\n",
       "  (126, 2.4175143241882324),\n",
       "  (127, 2.5645132064819336),\n",
       "  (128, 2.1735973358154297),\n",
       "  (129, 2.3190627098083496),\n",
       "  (130, 2.1826894283294678),\n",
       "  (131, 1.9968959093093872),\n",
       "  (132, 2.3693134784698486),\n",
       "  (133, 2.3921167850494385),\n",
       "  (134, 2.071448564529419),\n",
       "  (135, 2.3992114067077637),\n",
       "  (136, 1.8227791786193848),\n",
       "  (137, 2.3005623817443848),\n",
       "  (138, 2.357060670852661),\n",
       "  (139, 1.7307929992675781),\n",
       "  (140, 1.9397283792495728),\n",
       "  (141, 2.3732972145080566),\n",
       "  (142, 2.149714231491089),\n",
       "  (143, 2.131227493286133),\n",
       "  (144, 2.023275375366211),\n",
       "  (145, 2.277451276779175),\n",
       "  (146, 2.226242780685425),\n",
       "  (147, 2.147366762161255),\n",
       "  (148, 2.4248838424682617),\n",
       "  (149, 2.0110840797424316),\n",
       "  (150, 1.985538363456726),\n",
       "  (151, 2.102595090866089),\n",
       "  (152, 2.0838539600372314),\n",
       "  (153, 2.090721368789673),\n",
       "  (154, 1.8771113157272339),\n",
       "  (155, 1.9814059734344482),\n",
       "  (156, 1.8368295431137085),\n",
       "  (157, 2.098045825958252),\n",
       "  (158, 2.2342944145202637),\n",
       "  (159, 2.040363073348999),\n",
       "  (160, 1.9340717792510986),\n",
       "  (161, 2.284388542175293),\n",
       "  (162, 1.9464603662490845),\n",
       "  (163, 1.8168898820877075),\n",
       "  (164, 2.050400972366333),\n",
       "  (165, 2.1665432453155518),\n",
       "  (166, 2.098686695098877),\n",
       "  (167, 1.8510055541992188),\n",
       "  (168, 2.0651144981384277),\n",
       "  (169, 2.0044174194335938),\n",
       "  (170, 2.0588839054107666),\n",
       "  (171, 1.9888911247253418),\n",
       "  (172, 2.1916353702545166),\n",
       "  (173, 2.088520050048828),\n",
       "  (174, 1.9963057041168213),\n",
       "  (175, 1.8693426847457886),\n",
       "  (176, 2.1192731857299805),\n",
       "  (177, 2.181900978088379),\n",
       "  (178, 2.2705531120300293),\n",
       "  (179, 2.300130605697632),\n",
       "  (180, 2.2719287872314453),\n",
       "  (181, 2.09065580368042),\n",
       "  (182, 1.7797257900238037),\n",
       "  (183, 2.152729034423828),\n",
       "  (184, 1.9717464447021484),\n",
       "  (185, 1.9652645587921143),\n",
       "  (186, 1.7418365478515625),\n",
       "  (187, 2.025690793991089),\n",
       "  (188, 1.7649400234222412),\n",
       "  (189, 2.3085522651672363),\n",
       "  (190, 2.2766366004943848),\n",
       "  (191, 1.5727438926696777),\n",
       "  (192, 2.1094846725463867),\n",
       "  (193, 2.2127509117126465),\n",
       "  (194, 2.038613796234131),\n",
       "  (195, 1.9716261625289917),\n",
       "  (196, 2.2487711906433105),\n",
       "  (197, 2.304887294769287),\n",
       "  (198, 2.2598557472229004),\n",
       "  (199, 1.6644518375396729),\n",
       "  (200, 2.3934693336486816),\n",
       "  (201, 1.8743619918823242)],\n",
       " 'val': [(20, 3.0396454334259033),\n",
       "  (40, 2.7719468474388123),\n",
       "  (60, 2.609231948852539),\n",
       "  (80, 2.4431623220443726),\n",
       "  (100, 2.3712793588638306),\n",
       "  (120, 2.404343366622925),\n",
       "  (140, 2.300700306892395),\n",
       "  (160, 2.254921615123749),\n",
       "  (180, 2.2279289960861206),\n",
       "  (200, 2.236545205116272)]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mle_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"validate\"\n",
    "\n",
    "load_model = os.path.join(config.log_root, \"data/saved_models/0000180.tar\") # model directory\n",
    "\n",
    "opt = Namespace(task = task, load_model = load_model) # opt\n",
    "\n",
    "\n",
    "# new batcher for evaluation\n",
    "task_batcher = TaskBatcher( # Batching obj\n",
    "    examples=test_data.to_dict('records'),\n",
    "    vocab=vocab, \n",
    "    mode='train', \n",
    "    batch_size=188, \n",
    "    single_pass=True)\n",
    "\n",
    "eval_processor = TaskEvaluate(vocab, task_batcher, opt, TaskModel) # Evaluation object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_generator completed reading all examples. No more data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rowancassius/Desktop/capstone/LSTM_Summarizer/data_util/batcher.py\", line 444, in text_generator\n",
      "    example = next(example_generator)\n",
      "StopIteration\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rowancassius/opt/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/rowancassius/opt/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/rowancassius/Desktop/capstone/LSTM_Summarizer/data_util/batcher.py\", line 425, in fill_example_queue\n",
      "    context, task, summary = next(input_gen) # read the next example from file. article and abstract are both strings.\n",
      "RuntimeError: generator raised StopIteration\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14911184"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(eval_processor.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing Batch...\n",
      "Summarizing Batch...\n",
      "Summarizing Batch...\n",
      "INFO:tensorflow:Finished reading dataset in single_pass mode.\n"
     ]
    }
   ],
   "source": [
    "decoded_sents, ref_sents, task_sents, context_sents = eval_processor.evaluate_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ref_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(decoded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = Rouge().get_scores(decoded_sents, ref_sents, avg = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.5231746168243703,\n",
       "  'p': 0.6946175278622088,\n",
       "  'r': 0.46071446617050515},\n",
       " 'rouge-2': {'f': 0.30014812891335485,\n",
       "  'p': 0.4127659574468086,\n",
       "  'r': 0.2661482553104892},\n",
       " 'rouge-l': {'f': 0.5232927180716093,\n",
       "  'p': 0.7001730834177643,\n",
       "  'r': 0.4579418682242525}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>decoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>review details</td>\n",
       "      <td>review details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>send comments from legal department to SENDER</td>\n",
       "      <td>send those legal department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>update SENDER of changes</td>\n",
       "      <td>bring up to date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>give SENDER weather data</td>\n",
       "      <td>offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>check if deals can be rolled or extended</td>\n",
       "      <td>perform this</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ref                      decoded\n",
       "0  review details                                 review details             \n",
       "1  send comments from legal department to SENDER  send those legal department\n",
       "2  update SENDER of changes                       bring up to date           \n",
       "3  give SENDER weather data                       offer                      \n",
       "4  check if deals can be rolled or extended       perform this               "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'ref': ref_sents, 'decoded': decoded_sents})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(config.log_root, 'data/test_results_2.csv'), sep = '\\t', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'packet' in vocab._word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'interview' in vocab._word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some training examples\n",
    "pd.DataFrame({'ref': ref_sents, 'decoded': decoded_sents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..\n",
    "..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in nltk.corpus.wordnet.words(): print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(nltk.corpus.wordnet.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
