{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Outside imports\n",
    "import os\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import train\n",
    "import evaluate\n",
    "import train_util\n",
    "import data_util.data\n",
    "import data_util.batcher\n",
    "import data_util.config\n",
    "import data_util.preprocess\n",
    "\n",
    "importlib.reload(data_util.preprocess)\n",
    "importlib.reload(train)\n",
    "importlib.reload(model)\n",
    "importlib.reload(evaluate)\n",
    "importlib.reload(train_util)\n",
    "importlib.reload(data_util.config)\n",
    "importlib.reload(data_util.data)\n",
    "importlib.reload(data_util.batcher)\n",
    "\n",
    "from train import *\n",
    "from evaluate import *\n",
    "from model import *\n",
    "from train_util import *\n",
    "from data_util.data import *\n",
    "from data_util.batcher import *\n",
    "from data_util.preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load real data\n",
    "data_path = os.path.join(config.log_root, 'data/context_task_data.tsv')\n",
    "dat = pd.read_csv(data_path, sep='\\t')\n",
    "\n",
    "# fill nas\n",
    "dat.fillna('', inplace=True)\n",
    "\n",
    "# train/test split\n",
    "np.random.seed(111)\n",
    "dat = dat.sample(frac=1)\n",
    "\n",
    "train_size = int(.8*dat.shape[0])\n",
    "train_data = dat[:train_size]\n",
    "test_data = dat[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the the data\n",
    "def prep_data(df):\n",
    "    df['Context'] = df['Context'].map(lambda x: article_process_text(x))\n",
    "    df['TaskSentence'] = df['TaskSentence'].map(lambda x: article_process_text(x))\n",
    "    df['Summary'] = df['Summary'].map(lambda x: summary_process_text(x))\n",
    "    return df\n",
    "train_data = prep_data(train_data)\n",
    "test_data = prep_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: <s>, </s>, [UNK], [PAD], [START] or [STOP] found in vocab file\n",
      "WARNING: <s>, </s>, [UNK], [PAD], [START] or [STOP] found in vocab file\n",
      "WARNING: <s>, </s>, [UNK], [PAD], [START] or [STOP] found in vocab file\n",
      "WARNING: <s>, </s>, [UNK], [PAD], [START] or [STOP] found in vocab file\n",
      "Finished constructing vocabulary of 6639 total words. Last word added: LANGUAGE\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab(os.path.join(config.log_root, 'data/vocab/vocab.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "T.manual_seed(123)\n",
    "if T.cuda.is_available():\n",
    "    T.cuda.manual_seed_all(123)\n",
    "    \n",
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mle = \"yes\"\n",
    "train_rl = \"no\"\n",
    "mle_weight = 1.0\n",
    "load_model = None\n",
    "new_lr = None\n",
    "rl_weight = 1 - mle_weight\n",
    "\n",
    "opt = Namespace(train_mle = train_mle, \n",
    "                train_rl = train_rl, \n",
    "                mle_weight = mle_weight, \n",
    "                load_model = load_model,\n",
    "                new_lr = new_lr, \n",
    "                rl_weight = rl_weight)\n",
    "\n",
    "task_batcher = TaskBatcher(\n",
    "    examples=train_data.to_dict('records'),\n",
    "    vocab=vocab,\n",
    "    mode='train',\n",
    "    batch_size=32,\n",
    "    single_pass=False\n",
    ")\n",
    "\n",
    "val_task_batcher = TaskBatcher( # Batching obj\n",
    "    examples=test_data.to_dict('records')[:200],\n",
    "    vocab=vocab, \n",
    "    mode='train', \n",
    "    batch_size=50, \n",
    "    single_pass=False\n",
    ")\n",
    "\n",
    "\n",
    "train_processor = TaskTrain(vocab, task_batcher, opt, TaskModel, val_task_batcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained embedding weights\n",
    "train_processor.model.load_embeddings(\"embedding_6639_200.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 mle_loss: 6.149 mle_loss_val: -100.0000\n",
      "iter: 2 mle_loss: 5.980 mle_loss_val: -100.0000\n",
      "iter: 3 mle_loss: 6.558 mle_loss_val: -100.0000\n",
      "iter: 4 mle_loss: 5.892 mle_loss_val: -100.0000\n",
      "iter: 5 mle_loss: 5.856 mle_loss_val: -100.0000\n",
      "iter: 6 mle_loss: 5.299 mle_loss_val: -100.0000\n",
      "iter: 7 mle_loss: 4.500 mle_loss_val: -100.0000\n",
      "iter: 8 mle_loss: 3.893 mle_loss_val: -100.0000\n",
      "iter: 9 mle_loss: 4.333 mle_loss_val: -100.0000\n",
      "iter: 10 mle_loss: 3.549 mle_loss_val: -100.0000\n",
      "iter: 11 mle_loss: 3.579 mle_loss_val: -100.0000\n",
      "iter: 12 mle_loss: 3.731 mle_loss_val: -100.0000\n",
      "iter: 13 mle_loss: 3.141 mle_loss_val: -100.0000\n",
      "iter: 14 mle_loss: 2.942 mle_loss_val: -100.0000\n",
      "iter: 15 mle_loss: 3.059 mle_loss_val: -100.0000\n",
      "iter: 16 mle_loss: 3.126 mle_loss_val: -100.0000\n",
      "iter: 17 mle_loss: 3.153 mle_loss_val: -100.0000\n",
      "iter: 18 mle_loss: 3.091 mle_loss_val: -100.0000\n",
      "iter: 19 mle_loss: 2.932 mle_loss_val: -100.0000\n",
      "iter: 20 mle_loss: 3.393 mle_loss_val: -100.0000\n",
      "iter: 21 mle_loss: 2.895 mle_loss_val: -100.0000\n",
      "iter: 22 mle_loss: 2.814 mle_loss_val: -100.0000\n",
      "iter: 23 mle_loss: 3.023 mle_loss_val: -100.0000\n",
      "iter: 24 mle_loss: 3.030 mle_loss_val: -100.0000\n",
      "iter: 25 mle_loss: 2.949 mle_loss_val: -100.0000\n",
      "iter: 26 mle_loss: 2.525 mle_loss_val: -100.0000\n",
      "iter: 27 mle_loss: 3.003 mle_loss_val: -100.0000\n",
      "iter: 28 mle_loss: 3.054 mle_loss_val: -100.0000\n",
      "iter: 29 mle_loss: 2.961 mle_loss_val: -100.0000\n",
      "iter: 30 mle_loss: 2.849 mle_loss_val: 2.9207\n",
      "model saved at: \n",
      " data/saved_models_2/0000030.tar\n",
      "iter: 31 mle_loss: 3.052 mle_loss_val: 2.9207\n",
      "iter: 32 mle_loss: 2.907 mle_loss_val: 2.9207\n",
      "iter: 33 mle_loss: 2.763 mle_loss_val: 2.9207\n",
      "iter: 34 mle_loss: 2.705 mle_loss_val: 2.9207\n",
      "iter: 35 mle_loss: 2.791 mle_loss_val: 2.9207\n",
      "iter: 36 mle_loss: 2.951 mle_loss_val: 2.9207\n",
      "iter: 37 mle_loss: 2.900 mle_loss_val: 2.9207\n",
      "iter: 38 mle_loss: 2.836 mle_loss_val: 2.9207\n",
      "iter: 39 mle_loss: 3.180 mle_loss_val: 2.9207\n",
      "iter: 40 mle_loss: 2.643 mle_loss_val: 2.9207\n",
      "iter: 41 mle_loss: 2.524 mle_loss_val: 2.9207\n",
      "iter: 42 mle_loss: 2.752 mle_loss_val: 2.9207\n",
      "iter: 43 mle_loss: 2.687 mle_loss_val: 2.9207\n",
      "iter: 44 mle_loss: 2.694 mle_loss_val: 2.9207\n",
      "iter: 45 mle_loss: 2.525 mle_loss_val: 2.9207\n"
     ]
    }
   ],
   "source": [
    "config.save_model_path = \"data/saved_models_2\"\n",
    "\n",
    "mle_losses = train_processor.trainIters(n_iters=400, report_every=1, save_every = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mle_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"validate\"\n",
    "\n",
    "load_model = os.path.join(config.log_root, \"data/saved_models/0000180.tar\") # model directory\n",
    "\n",
    "opt = Namespace(task = task, load_model = load_model) # opt\n",
    "\n",
    "\n",
    "# new batcher for evaluation\n",
    "task_batcher = TaskBatcher( # Batching obj\n",
    "    examples=test_data.to_dict('records'),\n",
    "    vocab=vocab, \n",
    "    mode='train', \n",
    "    batch_size=188, \n",
    "    single_pass=True)\n",
    "\n",
    "eval_processor = TaskEvaluate(vocab, task_batcher, opt, TaskModel) # Evaluation object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(eval_processor.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sents, ref_sents, task_sents, context_sents = eval_processor.evaluate_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ref_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(decoded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = Rouge().get_scores(decoded_sents, ref_sents, avg = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ref': ref_sents, 'decoded': decoded_sents})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(config.log_root, 'data/test_results_2.csv'), sep = '\\t', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'packet' in vocab._word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'interview' in vocab._word_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking certain words for presence in the vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"ensure\", \"indicate\", \"turn\", \"open\", \"add\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[w in vocab._word_to_id for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_words = train_data['Summary'].map(lambda x: x.split(' ', 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_words.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vocab = action_words.map(lambda w: w in vocab._word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(in_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vocab.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_words[~in_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[~in_vocab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2240 of 2256 verbs to start summaries are in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "action_words[~in_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[~in_vocab]['Labeler'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[~in_vocab]['Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
