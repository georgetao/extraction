{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outside imports\n",
    "import os\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load real data\n",
    "data_path = '/Users/rowancassius/Desktop/capstone/data/context_task_data.tsv'\n",
    "dat = pd.read_csv(data_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess \n",
    "importlib.reload(preprocess)\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary Modifications:\n",
    "* lowercase first letter\n",
    "* lowercase it and this\n",
    "* filter punctuation\n",
    "\n",
    "Article Modifications (ideal):\n",
    "* lowercase non-entities\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Remind him that my name is Ro-Ro, and this is Catherine's channel by the way, and you can reach me at 415-279-3799 or you can contact me at rowancassius@gmail.com or at my personal website which is www.yougotitMAN.com. By the way I may also work for Google at Mountain View CA. What do you think?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art = 'Google jus tiisued us 5 times that amount captain. Please do bbetter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENT_TAGS = {\n",
    "    'PERSON',\n",
    "    'NORP',\n",
    "    'FAC',\n",
    "    'ORG',\n",
    "    'GPE',\n",
    "    'LOC',\n",
    "    'PRODUCT',\n",
    "    'EVENT'\n",
    "    'WORK_OF_ART',\n",
    "    'LAW',\n",
    "    'LANGUAGE',\n",
    "    'DATE',\n",
    "    'TIME',\n",
    "    'PERCENT',\n",
    "    'MONEY',\n",
    "    'QUANTITY',\n",
    "    'ORDINAL',\n",
    "    'CARDINAL'\n",
    "}\n",
    "\n",
    "CAP_WORDS = {'SENDER', 'I'}.union(INFO_CATS, ENT_TAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "def process_text(text):\n",
    "    text = clean_info(text)\n",
    "    text = replace_NE(text)\n",
    "    text = re.sub(BLACK, '', text)\n",
    "    tokens = [t if t in CAP_WORDS else t.lower() for \n",
    "              t in word_tokenize(text)]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def replace_NE(text):\n",
    "    'Replace the named entities with their types'\n",
    "    ent_lab = {e.text: e.label_ for e in nlp(text).ents if \n",
    "               e.text not in INFO_CATS}\n",
    "    for ent, lab in ent_lab.items():\n",
    "        text = re.sub(ent, lab, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAP_TAGS = {'SENDER', 'I'}.union(ENT_TAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAP_TAGS = ENT_TAGS + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [t if t in CAP_TAGS else t.lower() for t in word_tokenize(sent)]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"The guy I'm watching on Home Watchers right 134 is Incredibly annoying SENDER who is at 6488-687. Yes, Please repeat that Arnold at 3:53.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_text(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NON_ENT = '|'.join(ENT_TAGS)\n",
    "# ps = process_sent(s)\n",
    "\n",
    "re.findall('(?!Incredibly)\\w+', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('|'.join(ENT_TAGS), lambdaprocess_sent(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
